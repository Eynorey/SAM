* * *

### SAM Initiative

###### Skill Access Manager

* * *

# Master Test Plan

###### Version 1.0

## Table of Contents

1.  [Introduction](#markdown-header-1.-Introduction)
    1.  [Purpose](# 11-purpose)
    -  [Scope](# 12-scope)
    -  [Scope](# 12-scope)
    -  [Document Terminology and Acronyms](# 13-document-terminology-and-acronyms)
    -  [References](# 14-references)
    -  [Document Structure](# 15-structure)
- [Evaluation Mission and Test Motivation]()
    1. [Background]()
    - [Evaluation Mission]()
    - [Test Motivators]()
-  [Test Approach](# 2---test-approach)
    1.  [Function Testing](# 21-function-testing)
    -  [User Interface Testing](# 22-user-interface-testing)
-  [Deliverables](# 3---deliverables)
    1.  [Reporting on Test Coverage](# 31-reporting-on-test-coverage)
    -  [Incident Logs and Change Requests](# 32-incident-logs-and-change-requests)
    -  [Additional automated functional Test Scripts](# 33-additional-automated-functional-test-scripts)
-  [Testing Workflow](# 4---testing-workflow)
-  [Environmental Needs](# 5---environmental-needs)
-  [Responsibilities, Staffing and Training Needs](# 6---responsibilities-staffing-and-training-needs)
-  [Milestones](# 7---milestones)
-  [Risks, Dependencies, Assumptions and Constraints](# 8---risks-dependencies-assumptions-and-constraints)

# Master Test Plan

## 1\. Introduction

## 1.1 Purpose

The purpose of the Iteration Test Plan is to gather all of the information necessary to plan and control the test effort for the Skill Access Manager. It describes the approach to testing the software, and is the top-level plan generated and used by managers to direct the test effort.
This Test Plan for the Skill Access Manager supports the following objectives:
- Identifies the items that should be targeted by the tests.
- Identifies the motivation for and ideas behind the test areas to be covered.
- Outlines the testing approach that will be used.
- Identifies the required resources and provides an estimate of the test efforts.
- Lists the deliverable elements of the test project.


### 1.2 Scope

The application is tested using three different methods, each of which has a different scope.
Unit tests only concern a single class or method each. This ensures, that the implemented code works independently. We decided to exclude code from our tests that is developed and provided or generated by the JHipster Framework, such as the Maintenance Dashboard, since it is in their responsibility.
This document shows the following types of testing:
- Unit tests
- User Interface Testing

### 1.3 Intended Audience

This test plan is intended for technically advanced readers. It does not describe the application and should only be read by active project developers that touch the testing area.

### 1.4 Document Terminology and Acronyms

Definitions, Acronyms and Abbreviations relevant for the interpretation of the present document can be found in the [Project Glossary](https://eynorey.visualstudio.com/SAM%20-%20Smartify%20The%20World/_apps/hub/agile-extensions.wiki.wiki#/wiki/ProjectGlossary).

### 1.5 References

| Title | Date | Publishing organization |
| --- | --- | --- |
| [Project Glossary](https://eynorey.visualstudio.com/SAM%20-%20Smartify%20The%20World/_apps/hub/agile-extensions.wiki.wiki#/wiki/ProjectGlossary) | 23/10/16 | SAM Initiative |
| [Project Blog](https://smartifytheworld.wordpress.com/) | 27/10/16 | SAM Initiative |
| [UC Specification Manage Course](https://eynorey.visualstudio.com/SAM%20-%20Smartify%20The%20World/_apps/hub/agile-extensions.wiki.wiki#/docs/UC-Specification-ManageCourse) | 11/11/16 | SAM Initiative |
| [UC Specification Register](https://eynorey.visualstudio.com/SAM%20-%20Smartify%20The%20World/_apps/hub/agile-extensions.wiki.wiki#/docs/UC-Specification-Register) | 11/11/16 | SAM Initiative |

## 2\. Test Approach

### 2.1 Function Testing

| | Description |
| --- | --- |
| Technique Objective: |[Exercise database access methods and processes independent of the UI so you can observe and log incorrect functioning target behavior or data corruption.] |
| Technique: | [Invoke each database access method and process, seeding each with 	valid and invalid data or requests for data.  Inspect the database to ensure the data has been populated as 	intended and all database events have occurred properly, or review the 	returned data to ensure that the correct data was retrieved for the 	correct reasons.] | 
| Oracles: | [Outline one or more strategies that can be used by the technique to accurately observe the outcomes of the test. The oracle combines elements of both the method by which the observation can be made and the characteristics of specific outcome that indicate probable success or failure. Ideally, oracles will be self-verifying, allowing automated tests to make an initial assessment of test pass or failure, however, be careful to mitigate the risks inherent in automated results determination.] | 
| Required Tools: | [The technique requires the following tools: | 
| Success Criteria: | [The technique supports the testing of all key database access methods and processes.] | 
| Special Considerations: | [Testing may require a DBMS development environment or drivers to enter or modify data directly in the databases. Processes should be invoked manually. Small or minimally sized databases (limited number of records) should be used to increase the visibility of any non-acceptable events.] |

### 2.2 User Interface Testing

| | Description |
| --- | --- |
| Technique Objective: | Ensure Functionality of Graphical User Interface |
| Technique: | User Interactions (mouse clicks, keyboard inputs,  browser navigation) are emulated by a tool called SeleniumCucumber. After that, the tool compares the interface's actual appearance with the expected one. If a discrepancy is detected, the tool will report an error.| 
| Oracles: | Test is successful if the graphical user interface has adopted a specific state. This state's occurance can be detected by automated checking for GUI elements like butons, labels, inputs... | 
| Required Tools: | SeleniumCucumber, Ruby, ChromeDriver | 
| Success Criteria: | All user interface tests have to be successful. | 
| Special Considerations: | The user has to receive e-mails at some points of the process. These steps can not be tested. |

## 3\. Deliverables

### 3.1 Reporting on Test Coverage

### 3.2 Incident Logs and Change Requests

### 3.3 Additional automated functional Test Scripts

## 4\. Testing Workflow

## 5\. Environmental Needs

## 6\. Responsibilities, Staffing and Training Needs

## 7\. Milestones

## 4\. Risks, Dependencies, Assumptions and Constraints