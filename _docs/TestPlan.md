* * *

### SAM Initiative

###### Skill Access Manager

* * *

# Master Test Plan

###### Version 1.0

## Table of Contents

1.  [Introduction](#markdown-header-1.-Introduction)
    1.  [Purpose](# 11-purpose)
    -  [Scope](# 12-scope)
    -  [Scope](# 12-scope)
    -  [Document Terminology and Acronyms](# 13-document-terminology-and-acronyms)
    -  [References](# 14-references)
    -  [Document Structure](# 15-structure)
- [Evaluation Mission and Test Motivation]()
    1. [Background]()
    - [Evaluation Mission]()
    - [Test Motivators]()
-  [Test Approach](# 2---test-approach)
    1.  [Unit Testing]()
    -  [User Interface Testing](# 22-user-interface-testing)
-  [Deliverables](# 3---deliverables)
    1.  [Test Evaluation Summaries](# 31-reporting-on-test-coverage)
    -  [Reporting on Test Coverage](# 32-incident-logs-and-change-requests)
    -  [Perceived Quality Reports](# 33-additional-automated-functional-test-scripts)
-  [Testing Workflow](# 4---testing-workflow)
-  [Environmental Needs](# 5---environmental-needs)
-  [Responsibilities, Staffing and Training Needs](# 6---responsibilities-staffing-and-training-needs)
-  [Milestones](# 7---milestones)
-  [Risks, Dependencies, Assumptions and Constraints](# 8---risks-dependencies-assumptions-and-constraints)

# Master Test Plan

## 1\. Introduction

## 1.1 Purpose

The purpose of the Iteration Test Plan is to gather all of the information necessary to plan and control the test effort for the Skill Access Manager. It describes the approach to testing the software, and is the top-level plan generated and used by managers to direct the test effort.
This Test Plan for the Skill Access Manager supports the following objectives:
- Identifies the items that should be targeted by the tests.
- Identifies the motivation for and ideas behind the test areas to be covered.
- Outlines the testing approach that will be used.
- Identifies the required resources and provides an estimate of the test efforts.
- Lists the deliverable elements of the test project.


### 1.2 Scope

The application is tested using three different methods, each of which has a different scope.
Unit tests only concern a single class or method each. This ensures, that the implemented code works independently. We decided to exclude code from our tests that is developed and provided or generated by the JHipster Framework, such as the Maintenance Dashboard, since it is in their responsibility.
This document shows the following types of testing:
- Unit tests
- User Interface Testing

### 1.3 Intended Audience

This test plan is intended for technically advanced readers. It does not describe the application and should only be read by active project developers that touch the testing area.

### 1.4 Document Terminology and Acronyms

Definitions, Acronyms and Abbreviations relevant for the interpretation of the present document can be found in the [Project Glossary](https://eynorey.visualstudio.com/SAM%20-%20Smartify%20The%20World/_apps/hub/agile-extensions.wiki.wiki#/wiki/ProjectGlossary).

### 1.5 References

| Title | Date | Publishing organization |
| --- | --- | --- |
| [Project Glossary](https://eynorey.visualstudio.com/SAM%20-%20Smartify%20The%20World/_apps/hub/agile-extensions.wiki.wiki#/wiki/ProjectGlossary) | 23/10/16 | SAM Initiative |
| [Project Blog](https://smartifytheworld.wordpress.com/) | 27/10/16 | SAM Initiative |
| [UC Specification Manage Course](https://eynorey.visualstudio.com/SAM%20-%20Smartify%20The%20World/_apps/hub/agile-extensions.wiki.wiki#/docs/UC-Specification-ManageCourse) | 11/11/16 | SAM Initiative |
| [UC Specification Register](https://eynorey.visualstudio.com/SAM%20-%20Smartify%20The%20World/_apps/hub/agile-extensions.wiki.wiki#/docs/UC-Specification-Register) | 11/11/16 | SAM Initiative |

## 2\. Evaluation Mission and Test Motivation
    
### 2.1 Background

The key reason we use testing is, that we want to ensure, that the code we already have works fine, that the use cases work and that new changes do not break the application.

### 2.2 Evaluation Mission

Testing is a crucial phase in the development cycle. It is necessary in order to exterminate technical bugs and important functional problems and  gives assurance of their absence.
Behaviour driven development – which we actively live out – actually includes functional and UI testing in it's core. It helps teams to communicate and verify the requirements in use cases over different technical and functional levels (from Techie to Manager).

### 2.3 Test Motivators

Due to the high code base the project has, we have to maintain and refactor our code regularly, every time a new use case is added. To ensure that future updates do not break the application. It's also very convenient, that a lot of tests are already provided or are generated by the framework from the specification.

## 3\. Test Approach

### 3.1 Unit Testing

The primary goal of unit testing is to take the smallest piece of testable software in the application, isolate it from the remainder of the code, and determine whether it behaves exactly as you expect. Each unit is tested separately before integrating them into modules to test the interfaces between modules. Unit testing has proven its value in that a large percentage of defects are identified during its use.

In our project we use the JUnit framework for Java.

| | Description |
| --- | --- |
| Technique Objective: |Ensure that the implemented code works properly and independently. |
| Technique: | Implement test methods using JUnit Framework and its annotations. | 
| Oracles: | Console Output, Calculated Code Coverage by SonarCube | 
| Required Tools: | Test Runner: IntelliJ IDEA or Gradle with SonarQube | 
| Success Criteria: | All tests pass. | 

### 3.2 User Interface Testing

User Interface (UI) testing verifies a user’s interaction with the software. The goal of UI testing is to ensure that the UI provides the user with the appropriate access and navigation through the functions of the target-of-test. In addition, UI testing ensures that the objects within the UI function as expected and conform to corporate or industry standards.

For our automated frontend tests we use programmable selenium webdrivers, that open a browser and simulate user input. The user actions are specified in Java test cases.

| | Description |
| --- | --- |
| Technique Objective: | Exercise the following to observe and log standards conformance and target behavior: |
| | - Navigation through the target-of-test reflecting business functions and requirements, including window-to-window, field-to- field, and use of access methods (tab keys, mouse movements, accelerator keys). |
| | - Window objects and characteristics can be exercised–such as menus, size, position, state, and focus. |
| Technique: | User Interactions (mouse clicks, keyboard inputs,  browser navigation) are emulated by a tool called SeleniumCucumber. After that, the tool compares the interface's actual appearance with the expected one. If a discrepancy is detected, the tool will report an error.| 
| Oracles: | Test is successful if the graphical user interface has adopted a specific state. This state's occurance can be detected by automated checking for GUI elements like butons, labels, inputs... | 
| Required Tools: | SeleniumCucumber, Ruby, ChromeDriver | 
| Success Criteria: | All user interface tests have to be successful. | 
| Special Considerations: | The user has to receive e-mails at some points of the process. These steps can not be tested. |

## 4\. Deliverables

### 3.1 Test Evaluation Summaries

The project has around 86 tests which are passing. Furthermore Visual Studio Team Services are used to the tests every time the master branch is pdated. The build will fail if the unit tests are failing.

![](test-summary.PNG)

### 3.2 Reporting on Test Coverage

After a successful build in Visual Studio Team Services, the resulting reports are uploaded to SonarQube. According to [SonarQube](https://sonarqube.com/dashboard?id=sam), the current test coverage is around 59%.

### 4.3 Perceived Quality Reports

The tool which is used for quality reports is also [SonarQube](https://sonarqube.com/dashboard?id=sam). It shows the amount of issues in the code as well as several metrics.

## 5\. Testing Workflow

Every developer can run tests out of his or her IDE manually. To check if the developed code is compatible with the existing code.

Furthermore, Unit Tests are executed every time when the master branch is updated. This is triggered by Visual Studio Team Services:

![](CI.PNG)

## 6\. Environmental Needs

### Base Software Elements in the Test Environment

| Software Element Name | Type and Other Notes |
| --- | --- | 
| JUnit | Unit Testing library |
| IntelliJ IDEA | Local Test Runner / IDE | 
| Chrome Webdriver | Local UI Test Runner; OS: PC, Linux and MAC; Browser: Chrome |
| Central Unit Test Runner | Visual Studio Team Services |

### Productivity and Support Tools

| Tool Category or Type | Tool Brand Name |
| --- | --- | 
| Test Management | IntelliJ IDEA |
| Test Coverage Monitor or Profiler | [SonarQube](https://sonarqube.com/dashboard?id=sam) | 
| Project Management | Visual Studio Team Services |
| Hoster | Azure |
| Metrics tool | [SonarQube](https://sonarqube.com/dashboard?id=sam) |

## 7\. Responsibilities, Staffing and Training Needs

Responsible for all testing topics, including User Interface and Unit test, is Dominik Wunderlich.
Other team members might have to be informed about the new Test Plan.

## 8\. Milestones

We want to keep over 50% code coverage.

## 9\. Risks

| Risk | Mitigation Strategy | Contingency (Risk is realized) |
| --- | --- | --- |
| Dependency Injection impedes isolated Unit Testing |Abstract into new unit | transfer method into new scope | 
|Unit test cannot be applied because of framework structure | Pay attention to feature and code linkage | Test via Integration test |